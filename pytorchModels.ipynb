{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import clean\n",
    "import process\n",
    "#import pytorchPipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import train_test_split\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings(style = 'range', threshold = 2.5):\n",
    "    \"\"\"Gets the ratings/interaction/user-item matrix\n",
    "    in the form we need to apply the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    style: str, optional\n",
    "        Options: 'range', 'pos_neg', 'zero_one'\n",
    "        The format of the ratings matrix (see process.py)\n",
    "        Defaults to 'range'\n",
    "    threshold: int, optional\n",
    "        The cutoff threshold for \"liking\" a beer; only\n",
    "        matters if style = 'pos_neg' or style = 'zero_one'\n",
    "        (see process.py)\n",
    "        Defaults to 2.5\n",
    "    \"\"\"\n",
    "    if style not in ['range', 'pos_neg', 'zero_one']:\n",
    "        raise Exception('Not a valid choice for style.')\n",
    "        \n",
    "    reviews = pd.read_csv('https://query.data.world/s/55cb4g2ccy2sbat45jzrwmfjfkp2d5?dws=00000')\n",
    "    reviews.review_time = pd.to_datetime(reviews.review_time,unit = 's')\n",
    "    clean_reviews = clean.remove_null_rows(reviews)\n",
    "    clean_reviews = clean.remove_dup_beer_rows(clean_reviews)\n",
    "    clean_reviews = clean.merge_similar_name_breweries(clean_reviews)\n",
    "    clean_reviews = clean.merge_brewery_ids(clean_reviews)\n",
    "    \n",
    "    if style == 'range':\n",
    "        return process.InteractionMatrixTransformer(clean_reviews).to_range().tocsr()\n",
    "    if style == 'pos_neg':\n",
    "        return process.InteractionMatrixTransformer(clean_reviews).to_positive_negative(threshold).tocsr()\n",
    "    if style == 'zero_one':\n",
    "        return process.InteractionMatrixTransformer(clean_reviews).to_zero_one(threshold).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \"\"\"Matrix factorization model.\n",
    "\n",
    "    - Initializes user and item embeddings (default to dimension 10).\n",
    "    - Forward pass is just a dot product between user and item latent vectors.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_users, num_items, emb_size = 10):\n",
    "        super().__init__()\n",
    "        self.user_emb = torch.nn.Embedding(num_users, emb_size)\n",
    "        self.item_emb = torch.nn.Embedding(num_items, emb_size)\n",
    "        # initializing weights\n",
    "        self.user_emb.weight.data.uniform_(0,1)\n",
    "        self.item_emb.weight.data.uniform_(0,1)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        return (self.user_emb(user) * self.item_emb(item)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(model, int_matrix, epochs = 10, lr = 0.001, wd = 0.0):\n",
    "    \"\"\"Trains the matrix factorization model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: MatrixFactorization\n",
    "        The instance of a matrix factorization model to train\n",
    "    int_matrix: scipy.sparse._csr.csr_matrix\n",
    "        The ratings/interaction/user-item matrix\n",
    "    epochs: int, optional\n",
    "        Number of epochs in training\n",
    "        Default is 10\n",
    "    lr: float, optional\n",
    "        Learning rate\n",
    "        Default is 0.001\n",
    "    wd: float, optional\n",
    "        Weight decay\n",
    "        Default is 0.0\n",
    "    \"\"\"\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = wd)  # learning rate\n",
    "    for i in range(epochs):\n",
    "        model.train() # put model in training mode (?)\n",
    "        \n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get mse for nonzero entries\n",
    "        rows, cols = int_matrix.nonzero() # (rows[i], cols[i]) across all i will be the coordinates of all nonzero entries of ratings.\n",
    "\n",
    "        pred = model(torch.tensor(rows), torch.tensor(cols))\n",
    "        actual = torch.tensor(int_matrix[rows, cols], dtype = torch.float32).squeeze() # squeeze just reshapes to the appropriate dim\n",
    "        \n",
    "        loss = F.mse_loss(pred, actual)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "            \n",
    "        print(\"After %.0f epochs, train loss %.10f\" % (i + 1,loss.item()))\n",
    "    print('Final RMSE: %.4f' % loss.item()**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_training(model, int_matrix, initial_lr = 0.01, decay_rate = 0.98, epochs = 100, wd = 0.0):\n",
    "    \"\"\"Standardizes training for matrix factorization\n",
    "    models with learning rate decaying as:\n",
    "    initial_lr * decay_rate^epoch\n",
    "    Stick to the default inputs to standardize training!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: MatrixFactorization\n",
    "        The instance of a matrix factorization model to train\n",
    "    int_matrix: scipy.sparse._csr.csr_matrix\n",
    "        The ratings/interaction/user-item matrix\n",
    "    epochs: int, optional\n",
    "        Number of epochs in training\n",
    "        Default is 10\n",
    "    initial_lr: float, optional\n",
    "        Learning rate\n",
    "        Default is 0.01\n",
    "    decay_rate: float, optional\n",
    "        Decay rate\n",
    "        Default is 1.0\n",
    "    wd: float, optional\n",
    "        Weight decay\n",
    "        Default is 0.0\n",
    "    \"\"\"\n",
    "    model.train() # put model in training mode (?)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, weight_decay = wd)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = decay_rate)\n",
    "    for i in range(epochs):\n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get mse for nonzero entries\n",
    "        rows, cols = int_matrix.nonzero() # (rows[i], cols[i]) across all i will be the coordinates of all nonzero entries of ratings.\n",
    "\n",
    "        pred = model(torch.tensor(rows), torch.tensor(cols))\n",
    "        actual = torch.tensor(int_matrix[rows, cols], dtype = torch.float32).squeeze() # squeeze just reshapes to the appropriate dim\n",
    "        \n",
    "        loss = F.mse_loss(pred, actual)\n",
    "\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "            \n",
    "        if i % 10 == 0:\n",
    "            print(\"After %.0f epochs, train loss %.10f\" % (i, loss.item()))\n",
    "    print('Final RMSE: %.4f' % loss.item()**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_matrix = get_ratings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k_range(model, int_matrix, user, threshold = 2.5, k = 10):\n",
    "    \"\"\"Compute recall at k for a given user in the case\n",
    "    where the ratings matrix was built using to_range.\n",
    "    This is the ratio of number of items the user \n",
    "    actually liked (determined by threshold) in the \n",
    "    top k predictions made by the model over the total \n",
    "    number of items the user actually liked.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    int_matrix: scipy.sparse._csr.csr_matrix\n",
    "        The ratings/interaction/user-item matrix\n",
    "    user: int\n",
    "        The index of the user for whom you want to compute recall at k\n",
    "    threshold: float, optional\n",
    "        The threshold used to determine if a user actually likes a beer\n",
    "        Defaults to 2.5\n",
    "    k: int, optional\n",
    "        The k parameter\n",
    "        Defaults to 10\n",
    "    \"\"\"\n",
    "    num_items = int_matrix.shape[1]\n",
    "    preds = model(torch.tensor(user), torch.arange(num_items)) # predicated ratings of all beers\n",
    "    topk_inds = torch.topk(preds, k).indices # indices of the top k predictions\n",
    "    \n",
    "    # get indices of the liked beers\n",
    "    x = torch.tensor(int_matrix[user].toarray()).squeeze()\n",
    "    inds_of_liked_beers = torch.where(x > threshold, 1, 0).squeeze().nonzero() # puts 1 in indices where x > thresh, 0 else then gets the nonzero indices\n",
    "    \n",
    "    if inds_of_liked_beers.shape[0] == 0:\n",
    "        #return 'no liked beers'\n",
    "        return (1, 0) # is this how this should go??\n",
    "    \n",
    "    intersect = np.intersect1d(topk_inds, inds_of_liked_beers)\n",
    "    #print(len(intersect), len(inds_of_liked_beers))\n",
    "    return len(intersect)/min(k, len(inds_of_liked_beers)), len(inds_of_liked_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k_nonrange(model, ratings, user, k = 10):\n",
    "    \"\"\"Compute recall at k for a given user in the case\n",
    "    where the ratings matrix was built using to_zero_one\n",
    "    or to_positive_negative. This is the ratio of number\n",
    "    of items the user actually liked (appear with 1 for\n",
    "    this user in the ratings matrix) in the top k predictions\n",
    "    made by the model over the total number of items the user\n",
    "    actually liked.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: MatrixFactorization\n",
    "        The instance of a matrix factorization model to be evaluated\n",
    "    ratings: scipy.sparse._csr.csr_matrix\n",
    "        The ratings/interaction/user-item matrix\n",
    "    user: int\n",
    "        The index of the user for whom you want to compute recall at k\n",
    "    k: int, optional\n",
    "        The k parameter\n",
    "        Defaults to 10\n",
    "    \"\"\"\n",
    "    num_items = ratings.shape[1]\n",
    "    preds = model(torch.tensor(user), torch.arange(num_items)) # predicated ratings of all beers\n",
    "    topk_inds = torch.topk(preds, k).indices # indices of the top k predictions\n",
    "    \n",
    "    # get indices of the liked beers\n",
    "    x = torch.tensor(ratings[user].toarray())\n",
    "    inds_of_liked_beers = torch.where(x == 1, 1, 0).squeeze().nonzero() # puts 1 in indices where x == 1, 0 else then gets the nonzero indices\n",
    "    \n",
    "    if inds_of_liked_beers.shape[0] == 0:\n",
    "        #return 'no liked beers'\n",
    "        return 1 # is this how this should be handled??\n",
    "    \n",
    "    intersect = np.intersect1d(topk_inds, inds_of_liked_beers)\n",
    "    \n",
    "    return len(intersect)/min(k, len(inds_of_liked_beers)) # we use len(inds_of_liked_beers) for the weighted avg part below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submatrix(original_matrix, indices):\n",
    "    rows = indices[:,0]\n",
    "    cols = indices[:,1]\n",
    "    original_matrix_coo = sp.sparse.coo_matrix(original_matrix)\n",
    "    new_indices = np.where((np.isin(original_matrix_coo.row, rows)) & (np.isin(original_matrix_coo.col, cols)))\n",
    "    return sp.sparse.coo_matrix((original_matrix_coo.data[new_indices], (original_matrix_coo.row[new_indices], original_matrix_coo.col[new_indices])),\n",
    "                       shape=original_matrix.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_with_validation(int_matrix, threshold = 2.5, k = 10, latent_dim = 10):\n",
    "    recall_vals = [0]*5\n",
    "    preds = [0]*5\n",
    "    num_users = int_matrix.shape[0]\n",
    "    num_items = int_matrix.shape[1]\n",
    "    i = 0\n",
    "    for train, test in train_test_split.get_splits(int_matrix):\n",
    "        \n",
    "        print(\"Pass %d\"%i)\n",
    "        \n",
    "        model = MatrixFactorization(num_users, num_items, emb_size=latent_dim)\n",
    "        \n",
    "        train_matrix = get_submatrix(int_matrix, train).tocsr()\n",
    "        test_matrix = get_submatrix(int_matrix, test).tocsr()\n",
    "        \n",
    "        standard_training(model, train_matrix)\n",
    "        #preds = model(torch.tensor(0), torch.arange(num_items)) # THIS DOESN'T SEEM RIGHT! THIS IS ONLY PREDICTING ON USER 0!\n",
    "        #topk_inds = torch.topk(preds, k).indices\n",
    "        recall = total_weighted_recall_at_k_range(model, sp.sparse.csr_matrix(test_matrix), threshold = threshold, k = k)\n",
    "        print('Recall: ' + str(recall))\n",
    "        recall_vals[i] = recall\n",
    "        i += 1\n",
    "    return recall_vals\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_weighted_recall_at_k_range(model, int_matrix, threshold = 2.5, k = 10):\n",
    "    num_users, num_items = int_matrix.shape\n",
    "    \n",
    "    recalls = torch.empty(num_users)\n",
    "    weights = torch.empty(num_users)\n",
    "    \n",
    "    for user in range(num_users):\n",
    "        recall_output = recall_at_k_range(model, int_matrix, user, threshold, k)\n",
    "        recalls[user] = recall_output[0]\n",
    "        weights[user] = recall_output[1]\n",
    "        \n",
    "    return (recalls*weights/weights.sum()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example code for subsetting a sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  4.2 0.  0. ]\n",
      " [2.3 0.  3.1 0. ]\n",
      " [0.  0.  1.5 0. ]\n",
      " [0.  0.  0.  5.7]]\n",
      "[[0.  0.  0.  0. ]\n",
      " [0.  0.  3.1 0. ]\n",
      " [0.  0.  0.  0. ]\n",
      " [0.  0.  0.  5.7]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Example row, column, and data arrays\n",
    "rows = np.array([0, 1, 2, 1, 3])\n",
    "cols = np.array([1, 2, 2, 0, 3])\n",
    "data = np.array([4.2, 3.1, 1.5, 2.3, 5.7])\n",
    "\n",
    "# Create the original sparse matrix\n",
    "original_matrix = coo_matrix((data, (rows, cols)))\n",
    "print(original_matrix.toarray())\n",
    "# Specify the desired row and column indices for the subset\n",
    "desired_rows = [1, 3]\n",
    "desired_cols = [2, 3]\n",
    "\n",
    "# Find the indices of non-zero elements in the specified rows and columns\n",
    "subset_indices = np.where((np.isin(original_matrix.row, desired_rows)) & (np.isin(original_matrix.col, desired_cols)))\n",
    "\n",
    "# Extract the subset of the sparse matrix\n",
    "subset_matrix = coo_matrix((original_matrix.data[subset_indices], (original_matrix.row[subset_indices], original_matrix.col[subset_indices])),\n",
    "                           shape=original_matrix.shape)\n",
    "\n",
    "print(subset_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(latent_dims): # latent dims is a list\n",
    "    outs = [[] for _ in range(len(latent_dims))]\n",
    "    # add other hyperparams to gridsearch over?\n",
    "    for i, latent_dim in enumerate(latent_dims):\n",
    "        outs[i].append(latent_dim)\n",
    "        cross_vals = run_model_with_validation(int_matrix, threshold = 2.5, k = 10, latent_dim = latent_dim)\n",
    "        outs[i].append(cross_vals)\n",
    "        outs[i].append(sum(cross_vals)/len(cross_vals))\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 0\n",
      "After 0 epochs, train loss 7.7581138611\n",
      "After 10 epochs, train loss 5.4908323288\n",
      "After 20 epochs, train loss 3.8248550892\n",
      "After 30 epochs, train loss 2.7144274712\n",
      "After 40 epochs, train loss 2.0222947598\n",
      "After 50 epochs, train loss 1.6009666920\n",
      "After 60 epochs, train loss 1.3404914141\n",
      "After 70 epochs, train loss 1.1734248400\n",
      "After 80 epochs, train loss 1.0617290735\n",
      "After 90 epochs, train loss 0.9841665030\n",
      "Final RMSE: 0.9661\n",
      "Recall: tensor(7.6291e-05)\n",
      "Pass 1\n",
      "After 0 epochs, train loss 7.7312870026\n",
      "After 10 epochs, train loss 5.4715399742\n",
      "After 20 epochs, train loss 3.8163933754\n",
      "After 30 epochs, train loss 2.7169013023\n",
      "After 40 epochs, train loss 2.0327737331\n",
      "After 50 epochs, train loss 1.6157244444\n",
      "After 60 epochs, train loss 1.3568497896\n",
      "After 70 epochs, train loss 1.1900007725\n",
      "After 80 epochs, train loss 1.0779623985\n",
      "After 90 epochs, train loss 0.9998914003\n",
      "Final RMSE: 0.9740\n",
      "Recall: tensor(2.0786e-05)\n",
      "Pass 2\n",
      "After 0 epochs, train loss 7.7085523605\n",
      "After 10 epochs, train loss 5.4441967010\n",
      "After 20 epochs, train loss 3.7859549522\n",
      "After 30 epochs, train loss 2.6857466698\n",
      "After 40 epochs, train loss 2.0033266544\n",
      "After 50 epochs, train loss 1.5891833305\n",
      "After 60 epochs, train loss 1.3332880735\n",
      "After 70 epochs, train loss 1.1689988375\n",
      "After 80 epochs, train loss 1.0590122938\n",
      "After 90 epochs, train loss 0.9825478792\n",
      "Final RMSE: 0.9656\n",
      "Recall: tensor(0.)\n",
      "Pass 3\n",
      "After 0 epochs, train loss 7.7853150368\n",
      "After 10 epochs, train loss 5.5179934502\n",
      "After 20 epochs, train loss 3.8505425453\n",
      "After 30 epochs, train loss 2.7381682396\n",
      "After 40 epochs, train loss 2.0440731049\n",
      "After 50 epochs, train loss 1.6208800077\n",
      "After 60 epochs, train loss 1.3586690426\n",
      "After 70 epochs, train loss 1.1900643110\n",
      "After 80 epochs, train loss 1.0770721436\n",
      "After 90 epochs, train loss 0.9984525442\n",
      "Final RMSE: 0.9731\n",
      "Recall: tensor(0.)\n",
      "Pass 4\n",
      "After 0 epochs, train loss 7.6751637459\n",
      "After 10 epochs, train loss 5.4133052826\n",
      "After 20 epochs, train loss 3.7597804070\n",
      "After 30 epochs, train loss 2.6644372940\n",
      "After 40 epochs, train loss 1.9858257771\n",
      "After 50 epochs, train loss 1.5745147467\n",
      "After 60 epochs, train loss 1.3207486868\n",
      "After 70 epochs, train loss 1.1580736637\n",
      "After 80 epochs, train loss 1.0493183136\n",
      "After 90 epochs, train loss 0.9737978578\n",
      "Final RMSE: 0.9614\n",
      "Recall: tensor(0.0003)\n",
      "Pass 0\n",
      "After 0 epochs, train loss 3.0036106110\n",
      "After 10 epochs, train loss 1.3377450705\n",
      "After 20 epochs, train loss 0.8221175075\n",
      "After 30 epochs, train loss 0.6451414227\n",
      "After 40 epochs, train loss 0.5760411620\n",
      "After 50 epochs, train loss 0.5458117127\n",
      "After 60 epochs, train loss 0.5303339362\n",
      "After 70 epochs, train loss 0.5213914514\n",
      "After 80 epochs, train loss 0.5156161785\n",
      "After 90 epochs, train loss 0.5115735531\n",
      "Final RMSE: 0.7133\n",
      "Recall: tensor(0.)\n",
      "Pass 1\n",
      "After 0 epochs, train loss 2.9781520367\n",
      "After 10 epochs, train loss 1.3319110870\n",
      "After 20 epochs, train loss 0.8261400461\n",
      "After 30 epochs, train loss 0.6488676667\n",
      "After 40 epochs, train loss 0.5790881515\n",
      "After 50 epochs, train loss 0.5480896235\n",
      "After 60 epochs, train loss 0.5319564939\n",
      "After 70 epochs, train loss 0.5226065516\n",
      "After 80 epochs, train loss 0.5165696740\n",
      "After 90 epochs, train loss 0.5123494267\n",
      "Final RMSE: 0.7138\n",
      "Recall: tensor(0.0001)\n",
      "Pass 2\n",
      "After 0 epochs, train loss 3.0492539406\n",
      "After 10 epochs, train loss 1.3538950682\n",
      "After 20 epochs, train loss 0.8300533891\n",
      "After 30 epochs, train loss 0.6493722796\n",
      "After 40 epochs, train loss 0.5790489316\n",
      "After 50 epochs, train loss 0.5483271480\n",
      "After 60 epochs, train loss 0.5323986411\n",
      "After 70 epochs, train loss 0.5232157111\n",
      "After 80 epochs, train loss 0.5173064470\n",
      "After 90 epochs, train loss 0.5131761432\n",
      "Final RMSE: 0.7144\n",
      "Recall: tensor(0.)\n",
      "Pass 3\n",
      "After 0 epochs, train loss 2.9725215435\n",
      "After 10 epochs, train loss 1.3261003494\n",
      "After 20 epochs, train loss 0.8233627081\n",
      "After 30 epochs, train loss 0.6470541358\n",
      "After 40 epochs, train loss 0.5774906874\n",
      "After 50 epochs, train loss 0.5469319820\n",
      "After 60 epochs, train loss 0.5311125517\n",
      "After 70 epochs, train loss 0.5219643116\n",
      "After 80 epochs, train loss 0.5160734653\n",
      "After 90 epochs, train loss 0.5119587183\n",
      "Final RMSE: 0.7136\n",
      "Recall: tensor(0.)\n",
      "Pass 4\n",
      "After 0 epochs, train loss 3.0626738071\n",
      "After 10 epochs, train loss 1.3659173250\n",
      "After 20 epochs, train loss 0.8352820873\n",
      "After 30 epochs, train loss 0.6500240564\n",
      "After 40 epochs, train loss 0.5783461332\n",
      "After 50 epochs, train loss 0.5473078489\n",
      "After 60 epochs, train loss 0.5314305425\n",
      "After 70 epochs, train loss 0.5223432779\n",
      "After 80 epochs, train loss 0.5165242553\n",
      "After 90 epochs, train loss 0.5124702454\n",
      "Final RMSE: 0.7140\n",
      "Recall: tensor(0.0001)\n",
      "Pass 0\n",
      "After 0 epochs, train loss 2.9616391659\n",
      "After 10 epochs, train loss 0.9524842501\n",
      "After 20 epochs, train loss 0.6942738295\n",
      "After 30 epochs, train loss 0.6020095348\n",
      "After 40 epochs, train loss 0.5607119203\n",
      "After 50 epochs, train loss 0.5388663411\n",
      "After 60 epochs, train loss 0.5256772041\n",
      "After 70 epochs, train loss 0.5167106390\n",
      "After 80 epochs, train loss 0.5101718903\n",
      "After 90 epochs, train loss 0.5051791668\n",
      "Final RMSE: 0.7082\n",
      "Recall: tensor(8.3543e-05)\n",
      "Pass 1\n",
      "After 0 epochs, train loss 2.9513623714\n",
      "After 10 epochs, train loss 0.9408839345\n",
      "After 20 epochs, train loss 0.6921523809\n",
      "After 30 epochs, train loss 0.6021102071\n",
      "After 40 epochs, train loss 0.5608832836\n",
      "After 50 epochs, train loss 0.5391117334\n",
      "After 60 epochs, train loss 0.5259326696\n",
      "After 70 epochs, train loss 0.5169951320\n",
      "After 80 epochs, train loss 0.5104717016\n",
      "After 90 epochs, train loss 0.5054806471\n",
      "Final RMSE: 0.7085\n",
      "Recall: tensor(0.)\n",
      "Pass 2\n",
      "After 0 epochs, train loss 3.0101001263\n",
      "After 10 epochs, train loss 0.9612291455\n",
      "After 20 epochs, train loss 0.7006466985\n",
      "After 30 epochs, train loss 0.6068788767\n",
      "After 40 epochs, train loss 0.5642091036\n",
      "After 50 epochs, train loss 0.5415983796\n",
      "After 60 epochs, train loss 0.5280115008\n",
      "After 70 epochs, train loss 0.5188652873\n",
      "After 80 epochs, train loss 0.5122211576\n",
      "After 90 epochs, train loss 0.5071526170\n",
      "Final RMSE: 0.7096\n",
      "Recall: tensor(0.)\n",
      "Pass 3\n",
      "After 0 epochs, train loss 3.0478150845\n",
      "After 10 epochs, train loss 0.9684897661\n",
      "After 20 epochs, train loss 0.7022842765\n",
      "After 30 epochs, train loss 0.6075065732\n",
      "After 40 epochs, train loss 0.5647483468\n",
      "After 50 epochs, train loss 0.5422127247\n",
      "After 60 epochs, train loss 0.5286685824\n",
      "After 70 epochs, train loss 0.5195320845\n",
      "After 80 epochs, train loss 0.5128912926\n",
      "After 90 epochs, train loss 0.5078192949\n",
      "Final RMSE: 0.7101\n",
      "Recall: tensor(0.)\n",
      "Pass 4\n",
      "After 0 epochs, train loss 3.0302941799\n",
      "After 10 epochs, train loss 0.9655833244\n",
      "After 20 epochs, train loss 0.7030329108\n",
      "After 30 epochs, train loss 0.6061698198\n",
      "After 40 epochs, train loss 0.5638345480\n",
      "After 50 epochs, train loss 0.5415326357\n",
      "After 60 epochs, train loss 0.5282406807\n",
      "After 70 epochs, train loss 0.5192348361\n",
      "After 80 epochs, train loss 0.5126585364\n",
      "After 90 epochs, train loss 0.5076293349\n",
      "Final RMSE: 0.7100\n",
      "Recall: tensor(8.4373e-05)\n",
      "Pass 0\n",
      "After 0 epochs, train loss 78.0623092651\n",
      "After 10 epochs, train loss 23.8653926849\n",
      "After 20 epochs, train loss 7.5602526665\n",
      "After 30 epochs, train loss 3.1659376621\n",
      "After 40 epochs, train loss 1.9223498106\n",
      "After 50 epochs, train loss 1.4952884912\n",
      "After 60 epochs, train loss 1.3042557240\n",
      "After 70 epochs, train loss 1.1972500086\n",
      "After 80 epochs, train loss 1.1281282902\n",
      "After 90 epochs, train loss 1.0796878338\n",
      "Final RMSE: 1.0233\n",
      "Recall: tensor(0.0003)\n",
      "Pass 1\n",
      "After 0 epochs, train loss 77.0313873291\n",
      "After 10 epochs, train loss 23.4020328522\n",
      "After 20 epochs, train loss 7.3590383530\n",
      "After 30 epochs, train loss 3.0724816322\n",
      "After 40 epochs, train loss 1.8714003563\n",
      "After 50 epochs, train loss 1.4618104696\n",
      "After 60 epochs, train loss 1.2787710428\n",
      "After 70 epochs, train loss 1.1759943962\n",
      "After 80 epochs, train loss 1.1094489098\n",
      "After 90 epochs, train loss 1.0627535582\n",
      "Final RMSE: 1.0156\n",
      "Recall: tensor(0.0005)\n",
      "Pass 2\n",
      "After 0 epochs, train loss 77.2457962036\n",
      "After 10 epochs, train loss 23.4834690094\n",
      "After 20 epochs, train loss 7.3825345039\n",
      "After 30 epochs, train loss 3.0747985840\n",
      "After 40 epochs, train loss 1.8673353195\n",
      "After 50 epochs, train loss 1.4564784765\n",
      "After 60 epochs, train loss 1.2736966610\n",
      "After 70 epochs, train loss 1.1715124846\n",
      "After 80 epochs, train loss 1.1055459976\n",
      "After 90 epochs, train loss 1.0593358278\n",
      "Final RMSE: 1.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: tensor(0.0007)\n",
      "Pass 3\n",
      "After 0 epochs, train loss 77.5453948975\n",
      "After 10 epochs, train loss 23.6163883209\n",
      "After 20 epochs, train loss 7.4390497208\n",
      "After 30 epochs, train loss 3.1004498005\n",
      "After 40 epochs, train loss 1.8809591532\n",
      "After 50 epochs, train loss 1.4651373625\n",
      "After 60 epochs, train loss 1.2800519466\n",
      "After 70 epochs, train loss 1.1766390800\n",
      "After 80 epochs, train loss 1.1099274158\n",
      "After 90 epochs, train loss 1.0632195473\n",
      "Final RMSE: 1.0158\n",
      "Recall: tensor(0.0005)\n",
      "Pass 4\n",
      "After 0 epochs, train loss 78.4753952026\n",
      "After 10 epochs, train loss 24.0136985779\n",
      "After 20 epochs, train loss 7.5949940681\n",
      "After 30 epochs, train loss 3.1605939865\n",
      "After 40 epochs, train loss 1.9055587053\n",
      "After 50 epochs, train loss 1.4766212702\n",
      "After 60 epochs, train loss 1.2864940166\n",
      "After 70 epochs, train loss 1.1809742451\n",
      "After 80 epochs, train loss 1.1132746935\n",
      "After 90 epochs, train loss 1.0660420656\n",
      "Final RMSE: 1.0171\n",
      "Recall: tensor(0.0006)\n",
      "Pass 0\n",
      "After 0 epochs, train loss 452.6155090332\n",
      "After 10 epochs, train loss 174.1698455811\n",
      "After 20 epochs, train loss 71.9593811035\n",
      "After 30 epochs, train loss 34.9781799316\n",
      "After 40 epochs, train loss 20.4069232941\n",
      "After 50 epochs, train loss 13.8560094833\n",
      "After 60 epochs, train loss 10.4800186157\n",
      "After 70 epochs, train loss 8.5221138000\n",
      "After 80 epochs, train loss 7.2778410912\n",
      "After 90 epochs, train loss 6.4327011108\n",
      "Final RMSE: 2.4255\n",
      "Recall: tensor(0.0003)\n",
      "Pass 1\n",
      "After 0 epochs, train loss 449.2850341797\n",
      "After 10 epochs, train loss 172.5087432861\n",
      "After 20 epochs, train loss 71.1097564697\n",
      "After 30 epochs, train loss 34.5040283203\n",
      "After 40 epochs, train loss 20.1106777191\n",
      "After 50 epochs, train loss 13.6506719589\n",
      "After 60 epochs, train loss 10.3256349564\n",
      "After 70 epochs, train loss 8.3988704681\n",
      "After 80 epochs, train loss 7.1750187874\n",
      "After 90 epochs, train loss 6.3440093994\n",
      "Final RMSE: 2.4090\n",
      "Recall: tensor(0.0003)\n",
      "Pass 2\n",
      "After 0 epochs, train loss 454.6889038086\n",
      "After 10 epochs, train loss 175.2274169922\n",
      "After 20 epochs, train loss 72.5175323486\n",
      "After 30 epochs, train loss 35.3024749756\n",
      "After 40 epochs, train loss 20.6190242767\n",
      "After 50 epochs, train loss 14.0100269318\n",
      "After 60 epochs, train loss 10.6010255814\n",
      "After 70 epochs, train loss 8.6226701736\n",
      "After 80 epochs, train loss 7.3648090363\n",
      "After 90 epochs, train loss 6.5101513863\n",
      "Final RMSE: 2.4401\n",
      "Recall: tensor(0.0004)\n",
      "Pass 3\n",
      "After 0 epochs, train loss 454.9949035645\n",
      "After 10 epochs, train loss 175.3689422607\n",
      "After 20 epochs, train loss 72.5809936523\n",
      "After 30 epochs, train loss 35.3307800293\n",
      "After 40 epochs, train loss 20.6313877106\n",
      "After 50 epochs, train loss 14.0147390366\n",
      "After 60 epochs, train loss 10.6017837524\n",
      "After 70 epochs, train loss 8.6212224960\n",
      "After 80 epochs, train loss 7.3620457649\n",
      "After 90 epochs, train loss 6.5065579414\n",
      "Final RMSE: 2.4392\n",
      "Recall: tensor(0.0007)\n",
      "Pass 4\n",
      "After 0 epochs, train loss 454.0165405273\n",
      "After 10 epochs, train loss 174.8632354736\n",
      "After 20 epochs, train loss 72.3110961914\n",
      "After 30 epochs, train loss 35.1733436584\n",
      "After 40 epochs, train loss 20.5288524628\n",
      "After 50 epochs, train loss 13.9410743713\n",
      "After 60 epochs, train loss 10.5447368622\n",
      "After 70 epochs, train loss 8.5745697021\n",
      "After 80 epochs, train loss 7.3223452568\n",
      "After 90 epochs, train loss 6.4717488289\n",
      "Final RMSE: 2.4328\n",
      "Recall: tensor(0.0005)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[5,\n",
       "  [tensor(7.6291e-05),\n",
       "   tensor(2.0786e-05),\n",
       "   tensor(0.),\n",
       "   tensor(0.),\n",
       "   tensor(0.0003)],\n",
       "  tensor(7.8061e-05)],\n",
       " [10,\n",
       "  [tensor(0.), tensor(0.0001), tensor(0.), tensor(0.), tensor(0.0001)],\n",
       "  tensor(5.5913e-05)],\n",
       " [20,\n",
       "  [tensor(8.3543e-05), tensor(0.), tensor(0.), tensor(0.), tensor(8.4373e-05)],\n",
       "  tensor(3.3583e-05)],\n",
       " [50,\n",
       "  [tensor(0.0003),\n",
       "   tensor(0.0005),\n",
       "   tensor(0.0007),\n",
       "   tensor(0.0005),\n",
       "   tensor(0.0006)],\n",
       "  tensor(0.0005)],\n",
       " [100,\n",
       "  [tensor(0.0003),\n",
       "   tensor(0.0003),\n",
       "   tensor(0.0004),\n",
       "   tensor(0.0007),\n",
       "   tensor(0.0005)],\n",
       "  tensor(0.0004)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res = grid_search([5,10,20,50,100])\n",
    "grid_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grid_res), len(grid_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5\n",
      "1 10\n",
      "2 20\n",
      "3 50\n",
      "4 100\n"
     ]
    }
   ],
   "source": [
    "for i, dim in enumerate([5,10,20,50,100]):\n",
    "    print(i, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [grid_res[i][2] for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(7.8061e-05),\n",
       " tensor(5.5913e-05),\n",
       " tensor(3.3583e-05),\n",
       " tensor(0.0005),\n",
       " tensor(0.0004)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1d327cd76d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([5,10,20,50,100],vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
